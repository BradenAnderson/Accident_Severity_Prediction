{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14465f5e-6fac-4be3-907b-13465bd9101a",
   "metadata": {},
   "source": [
    "# Team Introduction\n",
    "Our group is comprised of Braden Anderson, Hien Lam, and Tavin Weeda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a912c08-32a2-41f9-8fce-01f6f419c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pickle \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, multilabel_confusion_matrix, ConfusionMatrixDisplay, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fa370a-cdb7-4967-98b0-747869450ed0",
   "metadata": {},
   "source": [
    "# Data Preparation Part 1\n",
    "- Define and prepare your class variables. \n",
    "- Use proper variable representations (int, float, one-hot, etc.). \n",
    "- Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. \n",
    "- Remove variables that are not needed/useful for the analysis.\n",
    "(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55355f40",
   "metadata": {},
   "source": [
    "## Read, clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa7e1851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data from github\n",
    "url_accident = \"https://github.com/BradenAnderson/Accident_Severity_Prediction/blob/main/Data/accident.csv.gz?raw=tr\"\n",
    "url_vehicle = \"https://github.com/BradenAnderson/Accident_Severity_Prediction/blob/main/Data/vehicle.csv.gz?raw=tr\"\n",
    "url_person = \"https://github.com/BradenAnderson/Accident_Severity_Prediction/blob/main/Data/person.csv.gz?raw=tr\"\n",
    "\n",
    "accident = pd.read_csv(url_accident,compression='gzip')\n",
    "vehicle = pd.read_csv(url_vehicle, compression='gzip', low_memory=False, encoding=\"ISO-8859-1\")\n",
    "person = pd.read_csv(url_person, compression='gzip', low_memory=False, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3238fbd5-1966-40db-9bd3-7d3c40f423c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter accidents where driver is present and vehicle is involved\n",
    "person = person.loc[(person.VEH_NO==1) & (person.PER_NO==1)]\n",
    "vehicle = vehicle.loc[vehicle.VEH_NO==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b101393b-d468-4864-97f0-6aa57a1985d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join person with vehicle and accident\n",
    "# Duplicated CASENUM are dropped\n",
    "df = person.merge(vehicle.drop_duplicates(subset=['CASENUM']), on='CASENUM', how='left')\n",
    "df = df.merge(accident.drop_duplicates(subset=['CASENUM']),on='CASENUM',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5231e351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54473, 24)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprehensive list of variables used in this analysis\n",
    "# ORIGINAL features from lab 1 / EDA: regionname, urbanicityname, body_typname, makename, mod_yearname, vtrafwayname, vnum_lanname, vsurcondname, vtrafconname, \n",
    "                                # typ_intname, int_hwyname, weathername, wkdy_imname, reljct1_imname, lgtcon_imname, maxsev_imname, alchl_imname, age_im, sex_imname, trav_sp\n",
    "# DERIVED features: hour_binned, speeding_status\n",
    "# NEW features post-lab 1 / EDA: rest_usename, pcrash1_imname, weather_binned (binning of `weathername`), body_type_binned (binning of `body_typname`), int_binned (binning of `typ_intname`)\n",
    "# DISCARDED features that were not useful: hour_imname (unnecessary with `hour_binned`), vspd_lim (unnecessary with `speeding_status`), makename (too many levels), wrk_zonename\n",
    "\n",
    "df = df[['REGIONNAME','URBANICITYNAME','BODY_TYPNAME_x', 'MOD_YEARNAME_x','VTRAFWAYNAME','VNUM_LANNAME','VSURCONDNAME','VTRAFCONNAME','TYP_INTNAME','INT_HWYNAME','WEATHERNAME',\n",
    "        'WKDY_IMNAME', 'RELJCT1_IMNAME','LGTCON_IMNAME','MAXSEV_IMNAME','ALCHL_IMNAME','AGE_IM','SEX_IMNAME','TRAV_SP','REST_USENAME','PCRASH1_IMNAME','HOUR_IMNAME','VSPD_LIM',\n",
    "        'HOUR_IM']]\n",
    "\n",
    "df = df.rename(columns=str.lower)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "486ba7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 54473 entries, 0 to 54472\n",
      "Data columns (total 24 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   regionname      54473 non-null  object \n",
      " 1   urbanicityname  54473 non-null  object \n",
      " 2   body_typname_x  54473 non-null  object \n",
      " 3   mod_yearname_x  54473 non-null  object \n",
      " 4   vtrafwayname    54427 non-null  object \n",
      " 5   vnum_lanname    54427 non-null  object \n",
      " 6   vsurcondname    54427 non-null  object \n",
      " 7   vtrafconname    54427 non-null  object \n",
      " 8   typ_intname     54473 non-null  object \n",
      " 9   int_hwyname     54473 non-null  object \n",
      " 10  weathername     54473 non-null  object \n",
      " 11  wkdy_imname     54473 non-null  object \n",
      " 12  reljct1_imname  54473 non-null  object \n",
      " 13  lgtcon_imname   54473 non-null  object \n",
      " 14  maxsev_imname   54473 non-null  object \n",
      " 15  alchl_imname    54473 non-null  object \n",
      " 16  age_im          54473 non-null  int64  \n",
      " 17  sex_imname      54473 non-null  object \n",
      " 18  trav_sp         54427 non-null  float64\n",
      " 19  rest_usename    54473 non-null  object \n",
      " 20  pcrash1_imname  54427 non-null  object \n",
      " 21  hour_imname     54473 non-null  object \n",
      " 22  vspd_lim        54427 non-null  float64\n",
      " 23  hour_im         54473 non-null  int64  \n",
      "dtypes: float64(2), int64(2), object(20)\n",
      "memory usage: 10.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "44886f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regionname</th>\n",
       "      <th>urbanicityname</th>\n",
       "      <th>body_typname_x</th>\n",
       "      <th>mod_yearname_x</th>\n",
       "      <th>vtrafwayname</th>\n",
       "      <th>vnum_lanname</th>\n",
       "      <th>vsurcondname</th>\n",
       "      <th>vtrafconname</th>\n",
       "      <th>typ_intname</th>\n",
       "      <th>int_hwyname</th>\n",
       "      <th>...</th>\n",
       "      <th>maxsev_imname</th>\n",
       "      <th>alchl_imname</th>\n",
       "      <th>age_im</th>\n",
       "      <th>sex_imname</th>\n",
       "      <th>trav_sp</th>\n",
       "      <th>rest_usename</th>\n",
       "      <th>pcrash1_imname</th>\n",
       "      <th>hour_imname</th>\n",
       "      <th>vspd_lim</th>\n",
       "      <th>hour_im</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West (MT, ID, WA, OR, CA, NV, NM, AZ, UT, CO, ...</td>\n",
       "      <td>Rural Area</td>\n",
       "      <td>4-door sedan, hardtop</td>\n",
       "      <td>2018</td>\n",
       "      <td>Two-Way, Not Divided</td>\n",
       "      <td>Five lanes</td>\n",
       "      <td>Snow</td>\n",
       "      <td>Traffic control signal(on colors) not known wh...</td>\n",
       "      <td>Four-Way Intersection</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No Apparent Injury (O)</td>\n",
       "      <td>No Alcohol Involved</td>\n",
       "      <td>61</td>\n",
       "      <td>Female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Shoulder and Lap Belt Used</td>\n",
       "      <td>Going Straight</td>\n",
       "      <td>8:00am-8:59am</td>\n",
       "      <td>98.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South (MD, DE, DC, WV, VA, KY, TN, NC, SC, GA,...</td>\n",
       "      <td>Urban Area</td>\n",
       "      <td>4-door sedan, hardtop</td>\n",
       "      <td>2013</td>\n",
       "      <td>Two-Way, Not Divided</td>\n",
       "      <td>Two lanes</td>\n",
       "      <td>Dry</td>\n",
       "      <td>No Controls</td>\n",
       "      <td>Not an Intersection</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Suspected Minor Injury (B)</td>\n",
       "      <td>No Alcohol Involved</td>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Shoulder and Lap Belt Used</td>\n",
       "      <td>Going Straight</td>\n",
       "      <td>1:00am-1:59am</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South (MD, DE, DC, WV, VA, KY, TN, NC, SC, GA,...</td>\n",
       "      <td>Urban Area</td>\n",
       "      <td>Other or Unknown automobile type</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Two-Way, Divided, Unprotected Median</td>\n",
       "      <td>Four lanes</td>\n",
       "      <td>Dry</td>\n",
       "      <td>No Controls</td>\n",
       "      <td>T-Intersection</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No Apparent Injury (O)</td>\n",
       "      <td>No Alcohol Involved</td>\n",
       "      <td>27</td>\n",
       "      <td>Female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Not Reported</td>\n",
       "      <td>Going Straight</td>\n",
       "      <td>1:00pm-1:59pm</td>\n",
       "      <td>45.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>West (MT, ID, WA, OR, CA, NV, NM, AZ, UT, CO, ...</td>\n",
       "      <td>Rural Area</td>\n",
       "      <td>Compact Utility (Utility Vehicle Categories \"S...</td>\n",
       "      <td>2015</td>\n",
       "      <td>Two-Way,  Divided, Positive  Median Barrier</td>\n",
       "      <td>Two lanes</td>\n",
       "      <td>Snow</td>\n",
       "      <td>No Controls</td>\n",
       "      <td>Not an Intersection</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No Apparent Injury (O)</td>\n",
       "      <td>No Alcohol Involved</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Shoulder and Lap Belt Used</td>\n",
       "      <td>Going Straight</td>\n",
       "      <td>2:00pm-2:59pm</td>\n",
       "      <td>80.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Northeast (PA, NJ, NY, NH, VT, RI, MA, ME, CT)</td>\n",
       "      <td>Rural Area</td>\n",
       "      <td>Station Wagon (excluding van and truck based)</td>\n",
       "      <td>2004</td>\n",
       "      <td>Not Reported</td>\n",
       "      <td>Not Reported</td>\n",
       "      <td>Snow</td>\n",
       "      <td>Warning Sign</td>\n",
       "      <td>Not an Intersection</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No Apparent Injury (O)</td>\n",
       "      <td>No Alcohol Involved</td>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "      <td>998.0</td>\n",
       "      <td>Shoulder and Lap Belt Used</td>\n",
       "      <td>Negotiating a Curve</td>\n",
       "      <td>5:00pm-5:59pm</td>\n",
       "      <td>50.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          regionname urbanicityname  \\\n",
       "0  West (MT, ID, WA, OR, CA, NV, NM, AZ, UT, CO, ...     Rural Area   \n",
       "1  South (MD, DE, DC, WV, VA, KY, TN, NC, SC, GA,...     Urban Area   \n",
       "2  South (MD, DE, DC, WV, VA, KY, TN, NC, SC, GA,...     Urban Area   \n",
       "3  West (MT, ID, WA, OR, CA, NV, NM, AZ, UT, CO, ...     Rural Area   \n",
       "4     Northeast (PA, NJ, NY, NH, VT, RI, MA, ME, CT)     Rural Area   \n",
       "\n",
       "                                      body_typname_x mod_yearname_x  \\\n",
       "0                              4-door sedan, hardtop           2018   \n",
       "1                              4-door sedan, hardtop           2013   \n",
       "2                   Other or Unknown automobile type        Unknown   \n",
       "3  Compact Utility (Utility Vehicle Categories \"S...           2015   \n",
       "4      Station Wagon (excluding van and truck based)           2004   \n",
       "\n",
       "                                  vtrafwayname  vnum_lanname vsurcondname  \\\n",
       "0                         Two-Way, Not Divided    Five lanes         Snow   \n",
       "1                         Two-Way, Not Divided     Two lanes          Dry   \n",
       "2         Two-Way, Divided, Unprotected Median    Four lanes          Dry   \n",
       "3  Two-Way,  Divided, Positive  Median Barrier     Two lanes         Snow   \n",
       "4                                 Not Reported  Not Reported         Snow   \n",
       "\n",
       "                                        vtrafconname            typ_intname  \\\n",
       "0  Traffic control signal(on colors) not known wh...  Four-Way Intersection   \n",
       "1                                        No Controls    Not an Intersection   \n",
       "2                                        No Controls         T-Intersection   \n",
       "3                                        No Controls    Not an Intersection   \n",
       "4                                       Warning Sign    Not an Intersection   \n",
       "\n",
       "  int_hwyname  ...               maxsev_imname         alchl_imname age_im  \\\n",
       "0          No  ...      No Apparent Injury (O)  No Alcohol Involved     61   \n",
       "1          No  ...  Suspected Minor Injury (B)  No Alcohol Involved     23   \n",
       "2          No  ...      No Apparent Injury (O)  No Alcohol Involved     27   \n",
       "3         Yes  ...      No Apparent Injury (O)  No Alcohol Involved     20   \n",
       "4          No  ...      No Apparent Injury (O)  No Alcohol Involved     23   \n",
       "\n",
       "  sex_imname trav_sp                rest_usename       pcrash1_imname  \\\n",
       "0     Female    25.0  Shoulder and Lap Belt Used       Going Straight   \n",
       "1       Male    45.0  Shoulder and Lap Belt Used       Going Straight   \n",
       "2     Female    15.0                Not Reported       Going Straight   \n",
       "3       Male    65.0  Shoulder and Lap Belt Used       Going Straight   \n",
       "4       Male   998.0  Shoulder and Lap Belt Used  Negotiating a Curve   \n",
       "\n",
       "     hour_imname  vspd_lim hour_im  \n",
       "0  8:00am-8:59am      98.0       8  \n",
       "1  1:00am-1:59am      25.0       1  \n",
       "2  1:00pm-1:59pm      45.0      13  \n",
       "3  2:00pm-2:59pm      80.0      14  \n",
       "4  5:00pm-5:59pm      50.0      17  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "279f178e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "regionname         0\n",
       "urbanicityname     0\n",
       "body_typname_x     0\n",
       "mod_yearname_x     0\n",
       "vtrafwayname      46\n",
       "vnum_lanname      46\n",
       "vsurcondname      46\n",
       "vtrafconname      46\n",
       "typ_intname        0\n",
       "int_hwyname        0\n",
       "weathername        0\n",
       "wkdy_imname        0\n",
       "reljct1_imname     0\n",
       "lgtcon_imname      0\n",
       "maxsev_imname      0\n",
       "alchl_imname       0\n",
       "age_im             0\n",
       "sex_imname         0\n",
       "trav_sp           46\n",
       "rest_usename       0\n",
       "pcrash1_imname    46\n",
       "hour_imname        0\n",
       "vspd_lim          46\n",
       "hour_im            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NA values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e1d71d3-30c3-44c0-9aec-9b8eb4ddf245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54473, 24)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a5435c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NA values since they are low representation of the entire dataset\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "74dfcb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm NA values are removed\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "64da2c19-e982-43b5-8637-76c17962638d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54427, 24)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63063e8",
   "metadata": {},
   "source": [
    "### Inspect each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2b3802",
   "metadata": {},
   "source": [
    "#### Year of vehicle **(Continuous)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9f743701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016       3809\n",
       "2017       3722\n",
       "2019       3489\n",
       "2018       3356\n",
       "Unknown    2935\n",
       "           ... \n",
       "1972          1\n",
       "1932          1\n",
       "1953          1\n",
       "1959          1\n",
       "1969          1\n",
       "Name: mod_yearname_x, Length: 67, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mod_yearname_x\n",
    "# Remove unknown instances\n",
    "# Filter to years 1980+\n",
    "df.mod_yearname_x.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f6e0a697-edcb-4193-8dff-0a1adadc4843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54427, 24)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6cb3d7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unknown instances, convert to numeric dtype\n",
    "non_int_values = pd.to_numeric(df.mod_yearname_x, errors='coerce').isna()\n",
    "df = df[-non_int_values]\n",
    "df['mod_yearname_x'] = pd.to_numeric(df['mod_yearname_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6b6aed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to years 1980+\n",
    "df = df.loc[df['mod_yearname_x'] >= 1980]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "82dd7830-ccd0-45b1-9bbb-4e91e80910d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50930, 24)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949121f1",
   "metadata": {},
   "source": [
    "#### Age of driver **(Continuous)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c1fd948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age_im\n",
    "# Removed observations below 15 years old\n",
    "# Should we bin 80+ or leave as is?\n",
    "df = df.loc[df['age_im'] > 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eab515d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50705, 24)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc945fef",
   "metadata": {},
   "source": [
    "#### Traveling speed of vehicle **(Continuous)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f0bff7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28975"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trav_sp\n",
    "# Speed Greater Than 151 mph indicated as 997\n",
    "# Speed not reported indicated as 998\n",
    "# Speed reported as unknown indicated as 999\n",
    "# Discern number of rows lost if 997, 998, and 998 are removed\n",
    "# 28975 !! Will impute instead\n",
    "df.loc[df['trav_sp'] >= 997].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ea76e2c4-58a7-406f-8eb8-44383f2cf46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50705, 24)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020929e9",
   "metadata": {},
   "source": [
    "#### Sex of driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "56990deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      31519\n",
       "Female    19186\n",
       "Name: sex_imname, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sex_imname\n",
    "df.sex_imname.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b7a24d",
   "metadata": {},
   "source": [
    "#### Region where crash occurred\n",
    "\n",
    "- Northeast (PA, NJ, NY, NH, VT, RI, MA, ME, CT)\n",
    "- West (MT, ID, WA, OR, CA, NV, NM, AZ, UT, CO, WY, AK, HI)\n",
    "- Midwest (OH, IN, IL, MI, WI, MN, ND, SD, NE, IA, MO, KS)\n",
    "- South (MD, DE, DC, WV, VA, KY, TN, NC, SC, GA, FL, AL, MS, LA, AR, OK, TX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "23581329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "South        26481\n",
       "Midwest       9643\n",
       "West          8449\n",
       "Northeast     6132\n",
       "Name: regionname, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regionname\n",
    "df.loc[:, \"regionname\"] = df.loc[:,\"regionname\"].apply(lambda string: string.split()[0])\n",
    "df.regionname.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6b44be",
   "metadata": {},
   "source": [
    "#### Geographical area of the crash\n",
    "\n",
    "- Urban\n",
    "- Rural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7256b8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Urban    37472\n",
       "Rural    13233\n",
       "Name: urbanicityname, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# urbanicityname\n",
    "df[\"urbanicityname\"] = df.loc[:,\"urbanicityname\"].apply(lambda string: string.split()[0])\n",
    "df.urbanicityname.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2646b5d",
   "metadata": {},
   "source": [
    "#### Trafficway flow just prior to crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e55aec76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Two-Way, Not Divided                                     21560\n",
       "Not Reported                                              8451\n",
       "Two-Way,  Divided, Positive  Median Barrier               8346\n",
       "Two-Way, Divided, Unprotected Median                      6455\n",
       "Two-Way, Not Divided With a Continuous Left-Turn Lane     1860\n",
       "Non-Trafficway or Driveway Access                         1801\n",
       "Entrance/Exit Ramp                                        1217\n",
       "One-Way Trafficway                                         997\n",
       "Reported as Unknown                                         18\n",
       "Name: vtrafwayname, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vtrafwayname\n",
    "# Bin observations 'Not Reported', 'Reported as Unknown' into NR/UNK\n",
    "df.vtrafwayname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ac55b37a-53ea-4932-a078-b853c1869646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50705, 24)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f611459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin observations 'Not Reported', 'Reported as Unknown' into NR/UNK\n",
    "df['vtrafwayname'] = df['vtrafwayname'].replace(['Not Reported', 'Reported as Unknown'], 'NR/UNK')\n",
    "\n",
    "# Remove observations 'Not Reported', 'Reported as Unknown'\n",
    "# remove = ['Not Reported', 'Reported as Unknown']\n",
    "# df = df[df.vtrafwayname.isin(remove) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "41752e08-f2f9-4836-8554-36644a82ffb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50705, 24)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "46845573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Two-Way, Not Divided                                     21560\n",
       "NR/UNK                                                    8469\n",
       "Two-Way,  Divided, Positive  Median Barrier               8346\n",
       "Two-Way, Divided, Unprotected Median                      6455\n",
       "Two-Way, Not Divided With a Continuous Left-Turn Lane     1860\n",
       "Non-Trafficway or Driveway Access                         1801\n",
       "Entrance/Exit Ramp                                        1217\n",
       "One-Way Trafficway                                         997\n",
       "Name: vtrafwayname, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vtrafwayname.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a53c84b",
   "metadata": {},
   "source": [
    "#### Number of travel lanes just prior to crash. \n",
    "- Median: lanes in opposite directions are additive. \n",
    "- No median: lanes in traveling direction counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4670dce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Two lanes                            18000\n",
       "Not Reported                         14340\n",
       "Three lanes                           5775\n",
       "Four lanes                            4714\n",
       "Five lanes                            3535\n",
       "Non-Trafficway or Driveway Access     1801\n",
       "Six lanes                             1200\n",
       "One lane                               917\n",
       "Seven or more lanes                    407\n",
       "Reported as Unknown                     16\n",
       "Name: vnum_lanname, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vnum_lanname\n",
    "# Bin 'Not Reported', 'Reported as Unknown' as NR/UNK\n",
    "df.vnum_lanname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3b96e45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin 'Not Reported', 'Reported as Unknown' as NR/UNK\n",
    "df['vnum_lanname'] = df['vnum_lanname'].replace(['Not Reported', 'Reported as Unknown'], 'NR/UNK')\n",
    "\n",
    "# Remove observations 'Not Reported', 'Reported as Unknown'\n",
    "# remove = ['Not Reported', 'Reported as Unknown']\n",
    "# df = df[df.vnum_lanname.isin(remove) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9491587a-c7d2-4beb-acd0-4326833868bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50705, 24)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9abc30fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Two lanes                            18000\n",
       "NR/UNK                               14356\n",
       "Three lanes                           5775\n",
       "Four lanes                            4714\n",
       "Five lanes                            3535\n",
       "Non-Trafficway or Driveway Access     1801\n",
       "Six lanes                             1200\n",
       "One lane                               917\n",
       "Seven or more lanes                    407\n",
       "Name: vnum_lanname, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vnum_lanname.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbee98ac",
   "metadata": {},
   "source": [
    "#### Roadway surface condition just prior to crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "31e10a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dry                                  37880\n",
       "Wet                                   6681\n",
       "Not Reported                          3165\n",
       "Non-Trafficway or Driveway Access     1801\n",
       "Snow                                   487\n",
       "Ice/Frost                              325\n",
       "Water (Standing or Moving)             102\n",
       "Slush                                   92\n",
       "Mud, Dirt or Gravel                     87\n",
       "Reported as Unknown                     59\n",
       "Sand                                    15\n",
       "Other                                    7\n",
       "Oil                                      4\n",
       "Name: vsurcondname, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vsurcondname\n",
    "# Bin 'Not Reported', 'Reported as Unknown', 'Other' as NR/UNK/OTH\n",
    "df.vsurcondname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "adea358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin 'Not Reported', 'Reported as Unknown', 'Other' as NR/UNK/OTH\n",
    "df['vsurcondname'] = df['vsurcondname'].replace(['Not Reported', 'Reported as Unknown', 'Other'], 'NR/UNK/OTH')\n",
    "\n",
    "# Remove observations 'Not Reported', 'Reported as Unknown'\n",
    "# remove = ['Not Reported', 'Reported as Unknown', 'Other']\n",
    "# df = df[df.vsurcondname.isin(remove) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c6af41f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50705, 24)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "81aea6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dry                                  37880\n",
       "Wet                                   6681\n",
       "NR/UNK/OTH                            3231\n",
       "Non-Trafficway or Driveway Access     1801\n",
       "Snow                                   487\n",
       "Ice/Frost                              325\n",
       "Water (Standing or Moving)             102\n",
       "Slush                                   92\n",
       "Mud, Dirt or Gravel                     87\n",
       "Sand                                    15\n",
       "Oil                                      4\n",
       "Name: vsurcondname, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vsurcondname.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada0e7e3",
   "metadata": {},
   "source": [
    "#### Traffic controls in the vehicle’s environment just prior to crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eeaa0010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Controls                                                                     25691\n",
       "Traffic control signal(on colors) not known whether or not Pedestrian Signal    10520\n",
       "Not Reported                                                                     7737\n",
       "Stop Sign                                                                        4768\n",
       "Yield Sign                                                                        580\n",
       "Traffic control signal (on colors) with Pedestrian Signal                         520\n",
       "Warning Sign                                                                      251\n",
       "Traffic control signal (on colors) without Pedestrian Signal                      183\n",
       "Flashing Traffic Control Signal                                                   128\n",
       "Other Regulatory Sign                                                              94\n",
       "Other                                                                              67\n",
       "Railway Crossing Device                                                            49\n",
       "Person                                                                             47\n",
       "Reported as Unknown                                                                24\n",
       "Other Highway Traffic Signal                                                       17\n",
       "School Zone Sign/Device                                                            16\n",
       "Lane Use Control Signal                                                             9\n",
       "Unknown Highway Traffic Signal                                                      3\n",
       "Unknown Regulatory Sign                                                             1\n",
       "Name: vtrafconname, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vtrafconname\n",
    "# Bin 'Not Reported', 'Other Regulatory Sign', 'Other', 'Reported as Unknown', 'Other Highway Traffic Signal', 'Unknown Highway Traffic Signal', 'Unknown Regulatory Sign'\n",
    "df.vtrafconname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "48ff38d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin 'Not Reported', 'Other Regulatory Sign', 'Other', 'Reported as Unknown', 'Other Highway Traffic Signal', 'Unknown Highway Traffic Signal', 'Unknown Regulatory Sign'\n",
    "df['vtrafconname'] = df['vtrafconname'].replace(['Not Reported', 'Other Regulatory Sign', 'Other', 'Reported as Unknown', 'Other Highway Traffic Signal', 'Unknown Highway Traffic Signal', 'Unknown Regulatory Sign'], 'NR/UNK/OTH')\n",
    "\n",
    "# Remove observations 'Not Reported', 'Other', 'Reported as Unknown', 'Unknown Highway Traffic Signal', 'Unknown Regulatory Sign'\n",
    "# remove = ['Not Reported', 'Other', 'Reported as Unknown', 'Unknown Highway Traffic Signal', 'Unknown Regulatory Sign']\n",
    "# df = df[df.vtrafconname.isin(remove) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4dcc9536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Controls                                                                     25691\n",
       "Traffic control signal(on colors) not known whether or not Pedestrian Signal    10520\n",
       "NR/UNK/OTH                                                                       7943\n",
       "Stop Sign                                                                        4768\n",
       "Yield Sign                                                                        580\n",
       "Traffic control signal (on colors) with Pedestrian Signal                         520\n",
       "Warning Sign                                                                      251\n",
       "Traffic control signal (on colors) without Pedestrian Signal                      183\n",
       "Flashing Traffic Control Signal                                                   128\n",
       "Railway Crossing Device                                                            49\n",
       "Person                                                                             47\n",
       "School Zone Sign/Device                                                            16\n",
       "Lane Use Control Signal                                                             9\n",
       "Name: vtrafconname, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vtrafconname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e19f691f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50705, 24)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ca5472",
   "metadata": {},
   "source": [
    "#### Did crash occur at intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "88b7347e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No         46035\n",
       "Yes         4663\n",
       "Unknown        7\n",
       "Name: int_hwyname, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# int_hwyname\n",
    "# Remove 'Unknown'\n",
    "df.int_hwyname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9a17d573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     46035\n",
       "Yes     4663\n",
       "Name: int_hwyname, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop observations with Unknown\n",
    "df.drop(df[df['int_hwyname'] == 'Unknown'].index, inplace = True)\n",
    "df.int_hwyname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f76dc9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50698, 24)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536c4063",
   "metadata": {},
   "source": [
    "#### Name of weekday where crash occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b802bc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Friday       8427\n",
       "Thursday     7682\n",
       "Wednesday    7631\n",
       "Tuesday      7239\n",
       "Saturday     6986\n",
       "Monday       6938\n",
       "Sunday       5795\n",
       "Name: wkdy_imname, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wkdy_imname\n",
    "df.wkdy_imname.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d096c57",
   "metadata": {},
   "source": [
    "#### Relation to junction (crash's location with respect to presence in an interchange area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "294f483e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     47293\n",
       "Yes     3405\n",
       "Name: reljct1_imname, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reljct1_imname\n",
    "df.reljct1_imname.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2386f885",
   "metadata": {},
   "source": [
    "#### Lighting condition during time of crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fd0262d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Daylight                   34052\n",
       "Dark - Lighted              8468\n",
       "Dark - Not Lighted          5762\n",
       "Dusk                        1292\n",
       "Dawn                         774\n",
       "Dark - Unknown Lighting      339\n",
       "Other                         11\n",
       "Name: lgtcon_imname, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lgtcon_imname\n",
    "df.lgtcon_imname.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3362f3",
   "metadata": {},
   "source": [
    "#### Alcohol state of driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b783fd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Alcohol Involved    46713\n",
       "Alcohol Involved        3985\n",
       "Name: alchl_imname, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alchl_imname\n",
    "df.alchl_imname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "68955117-aa10-4d40-88cf-b4163a3c676f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50698, 24)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea7d7e4",
   "metadata": {},
   "source": [
    "### Newly derived features or careful binning of existing features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c2bfe1",
   "metadata": {},
   "source": [
    "#### Speeding status of driver (Braden) (Derived feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a8e60b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_speeding_feature(row):\n",
    "    \n",
    "    # Speed greater than 151 mph, you're speeding\n",
    "    if row[\"trav_sp\"] == 997:\n",
    "        return 'speeding'\n",
    "    \n",
    "    # If we know they were going 95 mph or faster, calling that speeding\n",
    "    # regardless of what the speed limit is, or if we even know ths speed limit.\n",
    "    elif row[\"trav_sp\"] < 152 and row[\"trav_sp\"] >= 95:\n",
    "        return 'speeding'\n",
    "    \n",
    "    # If the speed limit is unknown, speeding is unknown\n",
    "    elif row[\"vspd_lim\"] == 98 or row[\"vspd_lim\"] == 99:\n",
    "        return 'unknown'\n",
    "    \n",
    "    # If the traveling speed is unknown, speeding is unknown\n",
    "    elif row['trav_sp'] == 998 or row['trav_sp'] == 999:\n",
    "        return 'unknown'\n",
    "    \n",
    "    # If traveling faster than the speed limit, speeding\n",
    "    elif row['trav_sp'] > row['vspd_lim']:\n",
    "        return 'speeding'\n",
    "    else:\n",
    "        return 'not speeding'\n",
    "    \n",
    "df[\"speeding_status\"] = df.apply(lambda row: create_speeding_feature(row), axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd13646",
   "metadata": {},
   "source": [
    "#### Time of accident, hours binned (Braden) (Derived feature)\n",
    "\n",
    "- Morning (6am-noon)\n",
    "- Afternoon (noon-6pm)\n",
    "- Evening (6pm-midnight)\n",
    "- Night (midnight-6am)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6f0a8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here\n",
    "def create_binned_hours_feature(numeric_hour, night_hours=[0,1,2,3,4,21,22,23], morning_hours=[5,6,7,8,9,10,11], \n",
    "                                afternoon_hours=[12,13,14,15], evening_hours=[16,17,18,19,20]):\n",
    "    \n",
    "    # NOTE: numeric_hour is a value from the HOUR_IM column\n",
    "\n",
    "    # Default for night is 9pm-4:59am\n",
    "    if numeric_hour in night_hours:\n",
    "        return \"Night\"\n",
    "    \n",
    "    # Default for morning is 5am-11:59am\n",
    "    elif numeric_hour in morning_hours:\n",
    "        return \"Morning\"\n",
    "    \n",
    "    # Default for Afternoon is 12:00pm-3:59pm\n",
    "    elif numeric_hour in afternoon_hours:\n",
    "        return \"Afternoon\"\n",
    "    \n",
    "    # Default for evening is 4:00pm-8:59pm\n",
    "    elif numeric_hour in evening_hours:\n",
    "        return \"Evening\"\n",
    "    \n",
    "df[\"hour_binned\"] = df[\"hour_im\"].apply(lambda hour: create_binned_hours_feature(numeric_hour=hour))\n",
    "\n",
    "# After hour_im is used to create hour_binned, we no longer need hour_im\n",
    "df.drop(columns=\"hour_im\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dd34f053-bfd9-4efa-90d9-086265bfa4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50698 entries, 0 to 54471\n",
      "Data columns (total 25 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   regionname       50698 non-null  object \n",
      " 1   urbanicityname   50698 non-null  object \n",
      " 2   body_typname_x   50698 non-null  object \n",
      " 3   mod_yearname_x   50698 non-null  int64  \n",
      " 4   vtrafwayname     50698 non-null  object \n",
      " 5   vnum_lanname     50698 non-null  object \n",
      " 6   vsurcondname     50698 non-null  object \n",
      " 7   vtrafconname     50698 non-null  object \n",
      " 8   typ_intname      50698 non-null  object \n",
      " 9   int_hwyname      50698 non-null  object \n",
      " 10  weathername      50698 non-null  object \n",
      " 11  wkdy_imname      50698 non-null  object \n",
      " 12  reljct1_imname   50698 non-null  object \n",
      " 13  lgtcon_imname    50698 non-null  object \n",
      " 14  maxsev_imname    50698 non-null  object \n",
      " 15  alchl_imname     50698 non-null  object \n",
      " 16  age_im           50698 non-null  int64  \n",
      " 17  sex_imname       50698 non-null  object \n",
      " 18  trav_sp          50698 non-null  float64\n",
      " 19  rest_usename     50698 non-null  object \n",
      " 20  pcrash1_imname   50698 non-null  object \n",
      " 21  hour_imname      50698 non-null  object \n",
      " 22  vspd_lim         50698 non-null  float64\n",
      " 23  speeding_status  50698 non-null  object \n",
      " 24  hour_binned      50698 non-null  object \n",
      "dtypes: float64(2), int64(2), object(21)\n",
      "memory usage: 10.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2396d555",
   "metadata": {},
   "source": [
    "#### Body type of vehicle (Tavin) (Careful binning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "90969f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here\n",
    "\n",
    "df['body_type_binned']=df['body_typname_x']\n",
    "\n",
    "df['body_type_binned']=df['body_type_binned'].replace(to_replace=\n",
    "                                        ['4-door sedan, hardtop',\n",
    "                                       '2-door sedan,hardtop,coupe',\n",
    "                                       '3-door coupe','Sedan/Hardtop, number of doors unknown'\n",
    "                                        ],value=1)\n",
    "df['body_type_binned']=df['body_type_binned'].replace(to_replace=\n",
    "                                        'Compact Utility (Utility Vehicle Categories \\\"Small\" and \\\"Midsize\\\")',\n",
    "                                         value=2)\n",
    "df['body_type_binned']=df['body_type_binned'].replace(to_replace=\n",
    "                                                                                                                                                                                  [\"Auto-based pickup (includes E1 Camino, Caballero, Ranchero, SSR, G8-ST, Subaru Brat, Rabbit Pickup)\",\n",
    "                                        \"Light Pickup\",\n",
    "                                        \"Unknown (pickup style) light conventional truck type\",\n",
    "                                        \"Unknown light truck type\",\n",
    "                                        \"Unknown light vehicle type (automobile,utility vehicle, van, or light truck)\"\n",
    "                                        ],value=3)\n",
    "df['body_type_binned']=df['body_type_binned'].replace(to_replace=\n",
    "                                         ['Large utility (ANSI D16.1 Utility Vehicle Categories and \"Full Size\" and \"Large\")',\n",
    "                                        'Utility Vehicle, Unknown body type'\n",
    "                                         ],value=4)\n",
    "df['body_type_binned']=df['body_type_binned'].replace(to_replace=\n",
    "                                        ['ATV/ATC [All-Terrain Cycle]',\n",
    "                                        'Moped or motorized bicycle',\n",
    "                                        'Motor Scooter',\n",
    "                                        'Off-road Motorcycle',\n",
    "                                        'Other motored cycle type (mini-bikes, pocket motorcycles \"pocket bikes\")',\n",
    "                                        'Three-wheel Motorcycle (2 Rear Wheels)',\n",
    "                                        'Two Wheel Motorcycle (excluding motor scooters)',\n",
    "                                        'Unenclosed Three Wheel Motorcycle / Unenclosed Autocycle (1 Rear Wheel)',\n",
    "                                        'Unknown motored cycle type',\n",
    "                                        'Unknown Three Wheel Motorcycle Type'\n",
    "                                        ],value=5)\n",
    "df['body_type_binned']=df['body_type_binned'].replace(to_replace=\n",
    "                                        ['Station Wagon (excluding van and truck based)',\n",
    "                                        'Utility station wagon (includes suburban limousines, Suburban, Travellall, Grand Wagoneer)'\n",
    "                                        ],value=6)\n",
    "df['body_type_binned']=df['body_type_binned'].replace(to_replace=\n",
    "                                        ['3-door/2-door hatchback',\n",
    "                                        '5-door/4-door hatchback',\n",
    "                                        'Hatchback, number of doors unknown'\n",
    "                                        ],value=7)\n",
    "df['body_type_binned']=df['body_type_binned'].replace(to_replace=\n",
    "                                        ['Cross Country/Intercity Bus',\n",
    "                                        'Medium/Heavy Vehicle Based Motor Home',\n",
    "                                        'Other Bus Type',\n",
    "                                        'School Bus',\n",
    "                                        'Transit Bus (City Bus)',\n",
    "                                        'Unknown Bus Type'\n",
    "                                        ],value=8)\n",
    "df['body_type_binned']=df['body_type_binned'].replace(to_replace=\n",
    "                                        ['Cab Chassis Based (includes Rescue Vehicle, Light Stake, Dump, and Tow Truck)',\n",
    "                                        'Medium/heavy Pickup (GVWR greater than 10,000 lbs.)',\n",
    "                                        'Single-unit straight truck or Cab-Chassis (GVWR greater than 26,000 lbs.)',\n",
    "                                        'Single-unit straight truck or Cab-Chassis (GVWR range 10,001 to 19,500 lbs.)',\n",
    "                                        'Single-unit straight truck or Cab-Chassis (GVWR range 19,501 to 26,000 lbs.)',\n",
    "                                        'Single-unit straight truck or Cab-Chassis (GVWR unknown)',\n",
    "                                        'Truck-tractor (Cab only, or with any number of trailing unit; any weight)',\n",
    "                                        'Unknown if single-unit or combination unit Heavy Truck (GVWR greater than 26,000 lbs.)',\n",
    "                                        'Unknown if single-unit or combination unit Medium Truck (GVWR range 10,001 lbs. to 26,000 lbs.)',\n",
    "                                        'Unknown medium/heavy truck type'\n",
    "                                         ],value=9)\n",
    "df['body_type_binned']=df['body_type_binned'].replace(to_replace=\n",
    "                                        'Convertible(excludes sun-roof,t-bar)',\n",
    "                                           value=10)\n",
    "df['body_type_binned']=df['body_type_binned'].replace(to_replace=\n",
    "                                        ['Large Van-Includes van-based buses (B150-B350, Sportsman, Royal Maxiwagon, Ram, Tradesman,...)',\n",
    "                                        'Minivan (Chrysler Town and Country, Caravan, Grand Caravan, Voyager, Voyager, Honda-Odyssey, ...)',\n",
    "                                        'Other van type (Hi-Cube Van, Kary)',\n",
    "                                        'Step van (GVWR greater than 10,000 lbs.)',\n",
    "                                        'Step-van or walk-in van (GVWR less than or equal to 10,000 lbs.)',\n",
    "                                        'Unknown van type',\n",
    "                                        'Van-Based Bus GVWR greater than 10,000 lbs.'\n",
    "                                        ],value=11)\n",
    "df['body_type_binned']=df['body_type_binned'].replace(to_replace=\n",
    "                                        ['Construction equipment other than trucks (includes graders)',\n",
    "                                        'Farm equipment other than trucks',\n",
    "                                        'Golf Cart',\n",
    "                                        'Large Limousine-more than four side doors or stretched chassis',\n",
    "                                        'Low Speed Vehicle (LSV) / Neighborhood Electric Vehicle (NEV)',\n",
    "                                        'Not Reported',\n",
    "                                        'Other or Unknown automobile type',\n",
    "                                        'Other vehicle type (includes go-cart, fork-lift, city street sweeper dunes/swamp buggy)',\n",
    "                                        'Recreational Off-Highway Vehicle',\n",
    "                                        'Unknown body type',\n",
    "                                        'Unknown truck type (light/medium/heavy)',\n",
    "                                        ],value=12)\n",
    "\n",
    "##drop original column after binning\n",
    "df.drop(columns='body_typname_x', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107ac74f",
   "metadata": {},
   "source": [
    "#### Type of intersection (Careful binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2af0d14f-e1a9-4423-994b-4ba584f12cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50698 entries, 0 to 54471\n",
      "Data columns (total 25 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   regionname        50698 non-null  object \n",
      " 1   urbanicityname    50698 non-null  object \n",
      " 2   mod_yearname_x    50698 non-null  int64  \n",
      " 3   vtrafwayname      50698 non-null  object \n",
      " 4   vnum_lanname      50698 non-null  object \n",
      " 5   vsurcondname      50698 non-null  object \n",
      " 6   vtrafconname      50698 non-null  object \n",
      " 7   typ_intname       50698 non-null  object \n",
      " 8   int_hwyname       50698 non-null  object \n",
      " 9   weathername       50698 non-null  object \n",
      " 10  wkdy_imname       50698 non-null  object \n",
      " 11  reljct1_imname    50698 non-null  object \n",
      " 12  lgtcon_imname     50698 non-null  object \n",
      " 13  maxsev_imname     50698 non-null  object \n",
      " 14  alchl_imname      50698 non-null  object \n",
      " 15  age_im            50698 non-null  int64  \n",
      " 16  sex_imname        50698 non-null  object \n",
      " 17  trav_sp           50698 non-null  float64\n",
      " 18  rest_usename      50698 non-null  object \n",
      " 19  pcrash1_imname    50698 non-null  object \n",
      " 20  hour_imname       50698 non-null  object \n",
      " 21  vspd_lim          50698 non-null  float64\n",
      " 22  speeding_status   50698 non-null  object \n",
      " 23  hour_binned       50698 non-null  object \n",
      " 24  body_type_binned  50698 non-null  object \n",
      "dtypes: float64(2), int64(2), object(21)\n",
      "memory usage: 10.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.typ_intname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b36a896-40ad-4c14-852b-c1ebc6c25fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a30e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_category(row):\n",
    "    if row == 'Not an Intersection':\n",
    "        result = 'No'\n",
    "    elif row == 'Reported as Unknown':\n",
    "        result = 'Other'\n",
    "    elif row == 'Not Reported':\n",
    "        result = 'Other'\n",
    "    else:\n",
    "        result = 'Yes'\n",
    "    return result\n",
    "\n",
    "df['intersection_binned'] = df['typ_intname'].apply(intersection_category)\n",
    "df.intersection_binned.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f840c810",
   "metadata": {},
   "source": [
    "#### Weather during time of crash (Careful binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4881de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weathername\n",
    "df.weathername.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cae44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_cat(row):\n",
    "    if row == 'Cloudy':\n",
    "        return 'Not Clear'\n",
    "    elif row == 'Fog, Smog, Smoke':\n",
    "        return 'Not Clear' \n",
    "    elif row == 'Snow':\n",
    "        return 'Wintery'\n",
    "    elif row == 'Blowing Snow':\n",
    "        return 'Wintery'\n",
    "    elif row == 'Sleet or Hail':\n",
    "        return 'Wintery'\n",
    "    elif row == 'Freezing Rain or Drizzle':\n",
    "        return 'Wintery'\n",
    "    elif row == 'Severe Crosswinds':\n",
    "        return 'Windy'\n",
    "    elif row == 'Blowing Sand, Soil, Dirt':\n",
    "        return 'Windy'\n",
    "    elif row == 'Clear':\n",
    "        return 'Clear'\n",
    "    elif row == 'Rain':\n",
    "        return 'Rain'\n",
    "    else:\n",
    "        return 'Other'\n",
    "df['weather_binned'] = df['weathername'].apply(weather_cat)\n",
    "df.weather_binned.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68c4a4c",
   "metadata": {},
   "source": [
    "#### Restraint use by driver (Newly added feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7170273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rest_use\n",
    "df.rest_usename.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rest_use: bin into none, minimal, full, other\n",
    "def restraint_category(row):\n",
    "    if row == 'Shoulder and Lap Belt Used':\n",
    "        result = 'Full'\n",
    "    elif row == 'None Used/Not Applicable':\n",
    "        result = 'None'    \n",
    "    elif row == 'Lap Belt Only Used':\n",
    "        result = 'Minimal'\n",
    "    elif row == 'Shoulder Belt Only Used':\n",
    "        result = 'Minimal'\n",
    "    elif row == 'Restraint Used - Type Unknown':\n",
    "        result = 'Minimal'\n",
    "    else:\n",
    "        result = 'Other'\n",
    "    return result\n",
    "\n",
    "df['restraint_binned'] = df['rest_usename'].apply(restraint_category)\n",
    "df.restraint_binned.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c266993",
   "metadata": {},
   "source": [
    "#### What driver was doing right before crash (Newly added feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ba9736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcrash1_imname\n",
    "df.pcrash1_imname.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e2108e",
   "metadata": {},
   "source": [
    "#### **Response variable:** Maximum injury severity of driver (Careful binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832350d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxsev_imname\n",
    "df.maxsev_imname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a82c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Injured, Severity Unknown and Died Prior to Crash \n",
    "remove = ['Injured, Severity Unknown', 'Died Prior to Crash*']\n",
    "df = df[df.maxsev_imname.isin(remove) == False]\n",
    "df['maxsev_imname'] = df['maxsev_imname'].str[:-4]\n",
    "df.maxsev_imname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49050764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine No Apparent Injury, Possible Injury, Suspected Minor Injury into one bin\n",
    "# Combine Suspected Serious Injury and Fatal Injury into one bin\n",
    "df['maxsev_binned'] = df['maxsev_imname'].replace(to_replace={'Suspected Serious Injury':'Fatal', \n",
    "                                                              'Fatal Injury':'Fatal', \n",
    "                                                              'No Apparent Injury':'Not Fatal', \n",
    "                                                              'Possible Injury':'Not Fatal', \n",
    "                                                              'Suspected Minor Injury':'Not Fatal'})\n",
    "df.maxsev_binned.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfd5ce3",
   "metadata": {},
   "source": [
    "### End of data cleaning. Review final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea531a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features that are not useful for modeling or redundant post binning\n",
    "df = df[df.columns.difference(['body_typname_x', 'typ_intname', 'weathername', 'rest_usename', 'hour_imname', 'vspd_lim'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc714908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "# Recall duplicated casenum was taken cared of during merge\n",
    "# Here we check for duplicates of instances excluding `casenum`\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d624cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm there are zero NA values\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a576ab",
   "metadata": {},
   "source": [
    "## Begin data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e58045-8338-40a2-a4f3-9ba60a210e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"maxsev_binned\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08145813-73f1-4d7a-bfd6-8606dbba79b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to scale features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training set age column, and transform (scale) the training set age column\n",
    "train_df.loc[:, [\"age_im\"]] = scaler.fit_transform(X=train_df.loc[:, [\"age_im\"]])\n",
    "\n",
    "# Using means and standard deviations from training set, scale the test set\n",
    "test_df.loc[:, [\"age_im\"]] = scaler.transform(X=test_df.loc[:, [\"age_im\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbef9bdb-33fb-440c-97f1-b11efaf67494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for one hot encode\n",
    "features_to_ohe = [\"hour_binned\", \"intersection_binned\", \"lgtcon_imname\", \"pcrash1_imname\", \"regionname\", \n",
    "                   \"restraint_binned\", \"vtrafconname\", \"vtrafwayname\", \"weather_binned\", \"wkdy_imname\", \n",
    "                   \"vnum_lanname\", \"vsurcondname\", \"speeding_status\"]\n",
    "\n",
    "# Features that need to become binary\n",
    "binary_features = [\"urbanicityname\", \"alchl_imname\", \"reljct1_imname\", \"int_hwyname\", \"sex_imname\"]\n",
    "\n",
    "# List of all the features that are not being converted to binary, or being OneHotEncoder\n",
    "# (Just a list of all features not in either of the two lists above).\n",
    "non_encoded_features = [col for col in df.columns if col not in features_to_ohe + binary_features]\n",
    "\n",
    "# Map each soon to be binary feature to its two initial values\n",
    "binary_encoding_map = {feature:df[feature].unique().tolist() for feature in binary_features}\n",
    "\n",
    "# Instantiate the OrdinalEncoder that will create the binary columns\n",
    "ord_encoder = OrdinalEncoder(categories=[value for value in binary_encoding_map.values()])\n",
    "\n",
    "# Map each feature that will be OneHotEncoded to a list of all possible categories that feature can take on. \n",
    "oridnal_encoding_map = {feature:df[feature].unique().tolist() for feature in features_to_ohe}\n",
    "\n",
    "# Instantiate the OneHotEncoder, telling it what the possible categories are for each feature.\n",
    "oh_encoder = OneHotEncoder(categories=[value for value in oridnal_encoding_map.values()]) \n",
    "\n",
    "encoders = ColumnTransformer(transformers=[(\"ordinal_encoder\", ord_encoder, binary_features), \n",
    "                                           (\"one_hot_encoder\", oh_encoder, features_to_ohe)], \n",
    "                             remainder=\"passthrough\",\n",
    "                             sparse_threshold=0,\n",
    "                             n_jobs=-1)\n",
    "\n",
    "# Create a dataframe of all the encoded columns in the training set\n",
    "train_encoded_features = pd.DataFrame(encoders.fit_transform(train_df.drop(columns=non_encoded_features)), \n",
    "                                      columns=encoders.get_feature_names_out())\n",
    "\n",
    "# Remove the non-encoded versions, and add in the encoded-versions of all columns.\n",
    "# Creates a version of the training set where all columns that need to be encoded are now encoded.\n",
    "train_encoded_df = pd.concat(objs=[train_df.drop(columns=features_to_ohe+binary_features).reset_index(drop=True), \n",
    "                                   train_encoded_features.reset_index(drop=True)], \n",
    "                             axis='columns')\n",
    "\n",
    "# Create a dataframe of all encoded (one hot and ordinal) columns for the test set\n",
    "test_encoded_features = pd.DataFrame(encoders.transform(test_df.drop(columns=non_encoded_features)), \n",
    "                                     columns=encoders.get_feature_names_out())\n",
    "\n",
    "# Remove the non-encoded versions, and add in the encoded-versions of all columns.\n",
    "# Creates a version of the test set where all columns that need to be encoded are now encoded.\n",
    "test_encoded_df = pd.concat(objs=[test_df.drop(columns=features_to_ohe+binary_features).reset_index(drop=True), \n",
    "                                   test_encoded_features.reset_index(drop=True)], \n",
    "                             axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0152f65-7023-41c5-bad3-11c85a142a0a",
   "metadata": {},
   "source": [
    "#### Imputing travel speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e69d39-6dec-4cfd-9d2c-628c7900c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Set the placeholder values (which need to be imputed) to NaN\n",
    "train_encoded_df.loc[train_encoded_df[\"trav_sp\"].isin([997, 998, 999]), \"trav_sp\"] = np.nan\n",
    "test_encoded_df.loc[test_encoded_df[\"trav_sp\"].isin([997, 998, 999]), \"trav_sp\"] = np.nan\n",
    "\n",
    "# Set up version of training dataset to be used for imputing trav_sp\n",
    "imputer_train_df = train_encoded_df.copy(deep=True)\n",
    "imputer_train_df.drop(columns=[\"maxsev_binned\"], inplace=True)\n",
    "severity_ord_enc = OrdinalEncoder(categories=[[\"No Apparent Injury\", \"Possible Injury\", \"Suspected Minor Injury\", \"Suspected Serious Injury\", \"Fatal Injury\"]])\n",
    "imputer_train_df[\"maxsev_imname\"] = severity_ord_enc.fit_transform(X=imputer_train_df[\"maxsev_imname\"].to_numpy().reshape(-1,1))\n",
    "\n",
    "# Setting the minimum and maximum value the imputer can impute for a traveling speed. \n",
    "min_trav_sp = 15\n",
    "max_trav_sp = 151\n",
    "impute_min_values = [-np.inf if col != \"trav_sp\" else min_trav_sp for col in imputer_train_df.columns]\n",
    "impute_max_values = [np.inf if col != \"trav_sp\" else max_trav_sp for col in imputer_train_df.columns]\n",
    "\n",
    "# Instantiate the iterative imputer\n",
    "imputer = IterativeImputer(min_value=impute_min_values, \n",
    "                           max_value=impute_max_values,\n",
    "                           random_state=42)\n",
    "\n",
    "# Fit the iterative imputer on the training set, and impute the training set\n",
    "imputer_train_result = imputer.fit_transform(X=imputer_train_df)\n",
    "\n",
    "# Take the output of running iteratrive imputer on the train set, and convert it to a dataframe\n",
    "# Save the imputed version of traveling speed to train_encoded_df\n",
    "imputer_train_result_df = pd.DataFrame(imputer_train_result, \n",
    "                                       columns=imputer.get_feature_names_out())\n",
    "train_encoded_df[\"trav_sp_imputed\"] = imputer_train_result_df[\"trav_sp\"]\n",
    "\n",
    "# Set up the version of the test dataset that will run through the imputer\n",
    "imputer_test_df = test_encoded_df.copy(deep=True)\n",
    "imputer_test_df.drop(columns=[\"maxsev_binned\"], inplace=True)\n",
    "imputer_test_df[\"maxsev_imname\"] = severity_ord_enc.transform(X=imputer_test_df[\"maxsev_imname\"].to_numpy().reshape(-1,1))\n",
    "\n",
    "# Run the test data through the imputer\n",
    "imputer_test_result = imputer.transform(X=imputer_test_df)\n",
    "\n",
    "# Convert the output of running the test data through iterative imputer to a dataframe\n",
    "imputer_test_result_df = pd.DataFrame(imputer_test_result, \n",
    "                                      columns=imputer.get_feature_names_out())\n",
    "test_encoded_df[\"trav_sp_imputed\"] = imputer_test_result_df[\"trav_sp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71c6fc-29bf-4ed4-a4cc-6c91c6b025fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the Non-Imputed versions of travel speed, now that imputation has been performed\n",
    "train_imputed_df = train_encoded_df.drop(columns=\"trav_sp\")\n",
    "test_imputed_df = test_encoded_df.drop(columns=\"trav_sp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e273dd-e414-439a-8626-f51c7c4847ca",
   "metadata": {},
   "source": [
    "#### Scaling travel speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505fbd9-43b1-47a8-8104-527914b8ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the scaler on the training set\n",
    "train_imputed_df[\"trav_sp_scaled\"] = speed_scaler.fit_transform(train_imputed_df[\"trav_sp_imputed\"].to_numpy().reshape(-1,1))\n",
    "\n",
    "# Only transform on the test set (no data leakage)\n",
    "test_imputed_df[\"trav_sp_scaled\"] = speed_scaler.transform(test_imputed_df[\"trav_sp_imputed\"].to_numpy().reshape(-1,1))\n",
    "\n",
    "# Use these dataframes moving forward\n",
    "# The final, fully preprocessed dataframes (all features encoded and imputed as needed)\n",
    "# Using \"pp\" to stand for preprocessed\n",
    "train_pp_df = train_imputed_df.drop(columns=\"trav_sp_imputed\")\n",
    "test_pp_df = test_imputed_df.drop(columns=\"trav_sp_imputed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56336af-18dc-4a7f-ac7e-662049ddcb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c078d3-c0a2-4eaa-b54c-5685fbb97d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table of features with representation (int, float, one-hot)\n",
    "# will do after braden does OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2097c379-9be9-4c62-b99a-f695adc078b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for feature selection: random forest feature importance\n",
    "\n",
    "# We will plot importances for the top NUM_IMPORTANCES_TO_PLOT features (by mean score)\n",
    "# This will be used for rf, selectkbest and mutualinfo\n",
    "NUM_IMPORTANCES_TO_PLOT = 20\n",
    "\n",
    "# Split the train set into X and y\n",
    "X = train_pp_df.drop(columns=[\"maxsev_binned\", \"maxsev_imname\"])\n",
    "y = train_pp_df.loc[:, \"maxsev_binned\"]\n",
    "\n",
    "# Instantiate and fit the random forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Calculates the standard deviation of the importance score for each feature.\n",
    "# For each of the 100 trees in the random forest, get the importance scores for all 106 features.\n",
    "# Then take the standard deviation of those 100 scores for each of the 106 features.\n",
    "# Result is 106 standard deviations, where each standard deviation was calculated from 100 values. \n",
    "# https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "rf_importance_stds = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "\n",
    "# Create a dataframe of importance scores\n",
    "rf_importances_df = pd.DataFrame({\"feature_name\":rf.feature_names_in_, \n",
    "                                  \"mean_importance_score\":rf.feature_importances_, \n",
    "                                  \"std_importance_score\":rf_importance_stds})\n",
    "\n",
    "# Sort the dataframe, largest to smallest mean score\n",
    "rf_importances_df.sort_values(by=\"mean_importance_score\", ascending=False, inplace=True)\n",
    "\n",
    "# reset the index so it starts back at 1, don't keep the old index as a column\n",
    "rf_importances_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create a truncated version of the dataframe containing only the first NUM_IMPORTANCES_TO_PLOT rows\n",
    "rf_plot_df = rf_importances_df.loc[rf_importances_df.index < NUM_IMPORTANCES_TO_PLOT, :]\n",
    "\n",
    "# Create a horizontal bar plot of importance scores\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(18, 6))\n",
    "sns.barplot(y=\"feature_name\", x=\"mean_importance_score\", data=rf_plot_df, ax=ax, orient=\"h\")\n",
    "\n",
    "ax.set_title(\"Random Forest Feature Importance, with Target Accident Severity\", fontsize=20, weight=1000)\n",
    "ax.set_xlabel(\"Mean Importance Score\", size=20, weight=1_000)\n",
    "ax.set_ylabel(\"Features\", size=20, weight=1_000)\n",
    "ax.tick_params(axis='both', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc3d69-ab7e-4e3b-9718-05163082ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for feature selection: selectkbest\n",
    "\n",
    "# Split the train set into X and y\n",
    "X = train_pp_df.drop(columns=[\"maxsev_binned\", \"maxsev_imname\"])\n",
    "y = train_pp_df.loc[:, \"maxsev_binned\"]\n",
    "\n",
    "# Instantiate and fit the random forest classifier\n",
    "kselector = SelectKBest(k=NUM_IMPORTANCES_TO_PLOT)\n",
    "kselector.fit(X, y)\n",
    "\n",
    "# Create a dataframe of scores\n",
    "kbest_scores_df = pd.DataFrame({\"feature_name\":kselector.feature_names_in_, \n",
    "                                  \"score\":kselector.scores_, \n",
    "                                  \"p_value\":kselector.pvalues_})\n",
    "\n",
    "\n",
    "# Sort the dataframe, largest to smallest mean score\n",
    "kbest_scores_df.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "\n",
    "# reset the index so it starts back at 1, don't keep the old index as a column\n",
    "kbest_scores_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create a truncated version of the dataframe containing only the first NUM_IMPORTANCES_TO_PLOT rows\n",
    "kbest_plot_df = kbest_scores_df.loc[kbest_scores_df.index < NUM_IMPORTANCES_TO_PLOT, :]\n",
    "\n",
    "# Create a horizontal bar plot of importance scores\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(18, 6))\n",
    "sns.barplot(y=\"feature_name\", x=\"score\", data=kbest_plot_df, ax=ax, orient=\"h\")\n",
    "\n",
    "ax.set_title(\"Feature Importance Score from SelectKBest, with Target Accident Severity\", fontsize=20, weight=1000)\n",
    "ax.set_xlabel(\"Importance Score\", size=20, weight=1_000)\n",
    "ax.set_ylabel(\"Features\", size=20, weight=1_000)\n",
    "ax.tick_params(axis='both', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49e709-215f-493a-9072-0077ca4ad451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for feature selection: mutual information\n",
    "\n",
    "# NOTE: mutual info is only considering discrete features\n",
    "\n",
    "# Split the train set into X and y\n",
    "X = train_pp_df.drop(columns=[\"maxsev_binned\", \"maxsev_imname\", \"age_im\", \"mod_yearname_x\", \"trav_sp_scaled\"])\n",
    "y = train_pp_df.loc[:, \"maxsev_binned\"]\n",
    "\n",
    "# Instantiate and fit the mutual information module\n",
    "mutual_info = mutual_info_classif(X=X, y=y, discrete_features=True, n_neighbors=3, random_state=42)\n",
    "\n",
    "# Create a dataframe of scores\n",
    "mutual_info_df = pd.DataFrame({\"mutual_information\":mutual_info, \n",
    "                               \"feature_name\":X.columns.tolist()})\n",
    "\n",
    "# Sort the dataframe, largest to smallest score\n",
    "mutual_info_df.sort_values(by=\"mutual_information\", ascending=False, inplace=True)\n",
    "\n",
    "# reset the index so it starts back at 1, don't keep the old index as a column\n",
    "mutual_info_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create a truncated version of the dataframe containing only the first NUM_IMPORTANCES_TO_PLOT rows\n",
    "mutual_info_plot_df = mutual_info_df.loc[mutual_info_df.index < NUM_IMPORTANCES_TO_PLOT, :]\n",
    "\n",
    "# Create a horizontal bar plot of importance scores\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(18, 6))\n",
    "sns.barplot(y=\"feature_name\", x=\"mutual_information\", data=mutual_info_plot_df, ax=ax, orient=\"h\")\n",
    "\n",
    "ax.set_title(\"Mutual Information Feature Importance with Target Accident Severity\", fontsize=20, weight=1000)\n",
    "ax.set_xlabel(\"Mutual Information\", size=20, weight=1_000)\n",
    "ax.set_ylabel(\"Features\", size=20, weight=1_000)\n",
    "ax.tick_params(axis='both', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540d1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff945102-b71e-43aa-939a-928626b33371",
   "metadata": {},
   "source": [
    "# Data Preparation Part 2\n",
    "Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).\n",
    "(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0b5c7-a016-4e61-9ff2-f2d193c22067",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c275e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a6cdc-77e0-4f3a-b864-f38e3a643995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table of feature description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a80e3b7-a078-40ad-97b8-ecc6bc4fc91b",
   "metadata": {},
   "source": [
    "# Model and Evaluation 1\n",
    "- Choose and explain your evaluation metrics that you will use (i.e., accuracy, precision, recall, F-measure, or any metric we have discussed). \n",
    "- Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\n",
    "(10)\n",
    "\n",
    "**Classification:** \n",
    "The evaluation metric to classify driver's injury severity is F1. This is an appropriate metric because the response, injury severity, is a categorical variable. Due to the class imbalance, metrics such as accuracy is not desirable because the model could have a high no-information-rate i.e., choose the most populous category and be correct most of the time.\n",
    "\n",
    "**Regression:**\n",
    "The evaluation metric to classify driver's age is MSE. This is an appropriate metric because the response, age, is a continuous variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e112272-1b77-417f-84a4-7248649782b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4c611f7-9bbd-4c70-9592-81d8429a3843",
   "metadata": {},
   "source": [
    "# Model and Evaluation 2\n",
    "- Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). \n",
    "- Explain why your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time.\n",
    "(10)\n",
    "\n",
    "**Classification:** \n",
    "The method used to divide the data into train and test split is xxx because xxx.\n",
    "\n",
    "**Regression:**\n",
    "The method used to divide the data into train and test split is xxx because xxx. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8dfa80-f5b7-4165-8bde-5fe1f2c1a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to split data here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05fdd8d-d02e-4234-94ed-ecd1729401a4",
   "metadata": {},
   "source": [
    "# Model and Evaluation 3\n",
    "- Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). \n",
    "- Two modeling techniques must be new (but the third could be SVM or logistic regression). \n",
    "- Adjust parameters as appropriate to increase generalization performance using your chosen metric. \n",
    "- You must investigate different parameters of the algorithms!\n",
    "(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e01da-6f1b-4c1a-aee2-466c7fb8d2c4",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924aa287-3fae-4bf4-aec2-fa0a6a56e436",
   "metadata": {},
   "source": [
    "### LightGBM for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c59954e-bf72-4b38-99f9-055b9e197301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Split the train set into X and y\n",
    "# The extra .rename() is only because LightGBM didn't like some of the characters in the column names. (brackets)\n",
    "# https://stackoverflow.com/questions/60582050/lightgbmerror-do-not-support-special-json-characters-in-feature-name-the-same\n",
    "X = train_pp_df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x)).drop(columns=[\"maxsev_binned\", \"maxsev_imname\"])\n",
    "y = train_pp_df.loc[:, \"maxsev_binned\"]\n",
    "\n",
    "param_distributions = {'num_leaves':[21, 26, 31, 36, 41], \n",
    "                       'max_depth':[-1, 10], \n",
    "                       'learning_rate':[0.01, 0.05, 0.1, 0.15, 0.2, 0.3]}\n",
    "\n",
    "rs_severity_lgbm = RandomizedSearchCV(estimator=LGBMClassifier(boosting_type=\"gbdt\", random_state=42), \n",
    "                                      param_distributions=param_distributions, \n",
    "                                      n_iter=10, \n",
    "                                      scoring={'f1':make_scorer(f1_score, pos_label=\"Fatal\"), 'accuracy': make_scorer(accuracy_score)}, \n",
    "                                      refit='f1',\n",
    "                                      n_jobs=-1, \n",
    "                                      cv=10, \n",
    "                                      random_state=42, \n",
    "                                      return_train_score=True, \n",
    "                                      error_score=\"raise\")\n",
    "\n",
    "rs_severity_lgbm.fit(X, y)\n",
    "\n",
    "lgbm_rs_severity_df = pd.DataFrame(rs_severity_lgbm.cv_results_)\n",
    "\n",
    "# Sort the randomsearch results dataframe from highest to lowest test f1\n",
    "lgbm_rs_severity_df.sort_values(by=\"mean_test_f1\", ascending=False, inplace=True)\n",
    "\n",
    "# Reorder columns so its easier to see metrics\n",
    "first_columns = [\"mean_test_f1\", \"mean_train_f1\", \"mean_test_accuracy\", \"mean_train_accuracy\"]\n",
    "new_column_order = first_columns + [column for column in lgbm_rs_severity_df.columns if column not in first_columns]\n",
    "lgbm_rs_severity_df = lgbm_rs_severity_df.loc[:, new_column_order]\n",
    "\n",
    "# View the randomsearch results\n",
    "lgbm_rs_severity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d0f4a",
   "metadata": {},
   "source": [
    "### Random Forest for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde49c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_pp_df.drop(columns=[\"maxsev_binned\", \"maxsev_imname\"])\n",
    "y = train_pp_df.loc[:, \"maxsev_binned\"]\n",
    "\n",
    "param_distributions = {'n_estimators':[num_trees for num_trees in range(100, 300)], \n",
    "                       'max_depth':[None, 10, 11, 12, 13, 14, 15], \n",
    "                       'min_samples_split':[2, 5, 10], \n",
    "                       'min_samples_leaf':[1, 2, 3]}\n",
    "\n",
    "rs_severity_rf = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42), \n",
    "                                      param_distributions=param_distributions, \n",
    "                                      n_iter=10, \n",
    "                                      scoring={'f1':make_scorer(f1_score, pos_label=\"Fatal\"), 'accuracy': make_scorer(accuracy_score)}, \n",
    "                                      refit='f1',\n",
    "                                      n_jobs=-1, \n",
    "                                      cv=10, \n",
    "                                      random_state=42, \n",
    "                                      return_train_score=True, \n",
    "                                      error_score=\"raise\")\n",
    "\n",
    "rs_severity_rf.fit(X, y)\n",
    "\n",
    "rf_rs_severity_df = pd.DataFrame(rs_severity_rf.cv_results_)\n",
    "\n",
    "# Sort the randomsearch results dataframe from highest to lowest test f1\n",
    "rf_rs_severity_df.sort_values(by=\"mean_test_f1\", ascending=False, inplace=True)\n",
    "\n",
    "# Reorder columns so its easier to see metrics\n",
    "first_columns = [\"mean_test_f1\", \"mean_train_f1\", \"mean_test_accuracy\", \"mean_train_accuracy\"]\n",
    "new_column_order = first_columns + [column for column in rf_rs_severity_df.columns if column not in first_columns]\n",
    "rf_rs_severity_df = rf_rs_severity_df.loc[:, new_column_order]\n",
    "\n",
    "# View the randomsearch results\n",
    "rf_rs_severity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb234a5",
   "metadata": {},
   "source": [
    "### kNN for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b3e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_pp_df.drop(columns=[\"maxsev_binned\", \"maxsev_imname\"])\n",
    "y = train_pp_df.loc[:, \"maxsev_binned\"]\n",
    "\n",
    "param_distributions = {'n_neighbors':[num_neighbors for num_neighbors in range(4, 101)]}\n",
    "\n",
    "rs_severity_knn = RandomizedSearchCV(estimator=KNeighborsClassifier(), \n",
    "                                      param_distributions=param_distributions, \n",
    "                                      n_iter=10, \n",
    "                                      scoring={'f1':make_scorer(f1_score, pos_label=\"Fatal\"), 'accuracy': make_scorer(accuracy_score)}, \n",
    "                                      refit='f1',\n",
    "                                      cv=10, \n",
    "                                      random_state=42, \n",
    "                                      return_train_score=True, \n",
    "                                      error_score=\"raise\")\n",
    "\n",
    "rs_severity_knn.fit(X, y)\n",
    "\n",
    "#knn_rs_severity_df = pd.DataFrame(rs_severity_knn.cv_results_)\n",
    "\n",
    "# Sort the randomsearch results dataframe from highest to lowest test f1\n",
    "#knn_rs_severity_df.sort_values(by=\"mean_test_f1\", ascending=False, inplace=True)\n",
    "\n",
    "# Reorder columns so its easier to see metrics\n",
    "#first_columns = [\"mean_test_f1\", \"mean_train_f1\", \"mean_test_accuracy\", \"mean_train_accuracy\"]\n",
    "#new_column_order = first_columns + [column for column in knn_rs_severity_df.columns if column not in first_columns]\n",
    "#knn_rs_severity_df = knn_rs_severity_df.loc[:, new_column_order]\n",
    "\n",
    "# View the randomsearch results\n",
    "#knn_rs_severity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2133b7d-f88e-44d2-ba3c-14e69531b5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59456ac4-9247-442e-98e3-2836b6292b59",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fac5a7f-5251-4464-8dcf-3f161b823e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1af8e4c5",
   "metadata": {},
   "source": [
    "### Random Forest for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11ba1d-3345-4e78-9e92-d8161f9d69ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_pp_df.drop(columns=[\"age_im\"])\n",
    "y = train_pp_df.loc[:, \"age_im\"]\n",
    "\n",
    "param_distributions = {'n_estimators':[num_trees for num_trees in range(100, 300)], \n",
    "                       'max_depth':[None, 10, 11, 12, 13, 14, 15], \n",
    "                       'min_samples_split':[2, 5, 10], \n",
    "                       'min_samples_leaf':[1, 2, 3]}\n",
    "\n",
    "rs_severity_rf = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42), \n",
    "                                      param_distributions=param_distributions, \n",
    "                                      n_iter=10, \n",
    "                                      scoring={'RMSE':make_scorer(f1_score, pos_label=\"Fatal\"), 'accuracy': make_scorer(accuracy_score)}, \n",
    "                                      refit='f1',\n",
    "                                      n_jobs=-1, \n",
    "                                      cv=10, \n",
    "                                      random_state=42, \n",
    "                                      return_train_score=True, \n",
    "                                      error_score=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da8843b-f8fe-4f57-b22c-daf2bda911c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_pp_df.drop(columns=[\"age\"])\n",
    "y = train_pp_df.loc[:, \"maxsev_binned\"]\n",
    "\n",
    "param_distributions = {'n_estimators':[num_trees for num_trees in range(100, 300)], \n",
    "                       'max_depth':[None, 10, 11, 12, 13, 14, 15], \n",
    "                       'min_samples_split':[2, 5, 10], \n",
    "                       'min_samples_leaf':[1, 2, 3]}\n",
    "\n",
    "rs_severity_rf = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42), \n",
    "                                      param_distributions=param_distributions, \n",
    "                                      n_iter=10, \n",
    "                                      scoring={'f1':make_scorer(f1_score, pos_label=\"Fatal\"), 'accuracy': make_scorer(accuracy_score)}, \n",
    "                                      refit='f1',\n",
    "                                      n_jobs=-1, \n",
    "                                      cv=10, \n",
    "                                      random_state=42, \n",
    "                                      return_train_score=True, \n",
    "                                      error_score=\"raise\")\n",
    "\n",
    "rs_severity_rf.fit(X, y)\n",
    "\n",
    "rf_rs_severity_df = pd.DataFrame(rs_severity_rf.cv_results_)\n",
    "\n",
    "# Sort the randomsearch results dataframe from highest to lowest test f1\n",
    "rf_rs_severity_df.sort_values(by=\"mean_test_f1\", ascending=False, inplace=True)\n",
    "\n",
    "# Reorder columns so its easier to see metrics\n",
    "first_columns = [\"mean_test_f1\", \"mean_train_f1\", \"mean_test_accuracy\", \"mean_train_accuracy\"]\n",
    "new_column_order = first_columns + [column for column in rf_rs_severity_df.columns if column not in first_columns]\n",
    "rf_rs_severity_df = rf_rs_severity_df.loc[:, new_column_order]\n",
    "\n",
    "# View the randomsearch results\n",
    "rf_rs_severity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff7551d",
   "metadata": {},
   "source": [
    "### kNN for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42747aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22405b43",
   "metadata": {},
   "source": [
    "### SVM for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab1ff03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef1bb6a5-38d8-4cec-b6d5-4a85eaa5adf5",
   "metadata": {},
   "source": [
    "# Model and Evaluation 4\n",
    "- Analyze the results using your chosen method of evaluation. \n",
    "- Use visualizations of the results to bolster the analysis. \n",
    "- Explain any visuals and analyze why they are interesting to someone that might use this model.\n",
    "(10)\n",
    "\n",
    "We need one plot of the winning model from each task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed58e2a6",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17130637-287c-4f38-bd1a-0b5bb31c040a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a042243",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa36422b-c0c4-4f2e-91a5-678721e17fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d3e248b-338f-413a-9dcd-aa1fda118cb5",
   "metadata": {},
   "source": [
    "# Model and Evaluation 5\n",
    "- Discuss the advantages of each model for each classification task, if any. \n",
    "- If there are not advantages, explain why. Is any model better than another? \n",
    "- Is the difference significant with 95% confidence? Use proper statistical comparison methods. \n",
    "- You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course.\n",
    "(10)\n",
    "\n",
    "ROC plot of winning model from each task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc0d3f1",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8465d18-554b-4265-821c-6e458552722f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f997bcf",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baa2a71-3e66-4a3a-9716-0ff99ce3246b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "234c3b0f-a448-4b80-ab2e-90128b4da541",
   "metadata": {},
   "source": [
    "# Model and Evaluation 6 \n",
    "- Which attributes from your analysis are most important? \n",
    "- Use proper methods discussed in class to evaluate the importance of different attributes. \n",
    "- Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task.\n",
    "(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e44eda7-999d-4ca5-869c-16cbe4e81c30",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e040e-75b4-44b8-a8f2-e888b9ba43d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fd6b851",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c3fae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57a7c155-d9d0-4c69-b749-1f8395f18165",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "- How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? \n",
    "- How would you measure the model's value if it was used by these parties? \n",
    "- How would your deploy your model for interested parties? \n",
    "- What other data should be collected? How often would the model need to be updated, etc.? \n",
    "(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff5d52b",
   "metadata": {},
   "source": [
    "1. How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2048bc4e-eaed-4fcd-b042-2401cb39e454",
   "metadata": {},
   "source": [
    "2. How would you measure the model's value if it was used by these parties? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b85326",
   "metadata": {},
   "source": [
    "3. How would your deploy your model for interested parties? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff30158a",
   "metadata": {},
   "source": [
    "4. What other data should be collected? How often would the model need to be updated, etc.? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c97ea97-8fec-4f8b-b2d5-b54a9c43c8a3",
   "metadata": {},
   "source": [
    "# Exceptional Work\n",
    "- You have free reign to provide additional analyses. \n",
    "- One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. \n",
    "- Which parameters are most significant for making a good model for each classification algorithm?\n",
    "(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507c11cb-0977-4a4f-8f96-412c71ff8510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e713672-a835-4f20-a29f-c750c15054f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddffc747-da2c-4de2-8fab-ddb4b26b817f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf4d5f9-f728-4dd2-9b46-d719e6bf1fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
